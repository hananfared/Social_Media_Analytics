{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Name: Hanan Fared Mohamed Omara , ID =  20398559"
      ],
      "metadata": {
        "id": "ifWspB84bxpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science LifeCycle ü§ì\n",
        "- Business Understanding \n",
        " - the dataset combined with some available data. Some nosies are added to the dataset and is not clean so we need to clean it well , The goal is to predict which False information on the Internet has caused many social problems due to the raise of social network and its role in different domains such as politics. In this assignment, we are going to predict if a specific reddit post is fake news or not, by looking at its title. The data is raw (contains various forms of words), This is a binary classification task. we are going to predict the probability (0-1, float) that show if it is fake or not.\n",
        "- Load Dataset üòÉ\n",
        "  - The dataset is text in english language .\n",
        "  - Dataset on kaggle include two parts (train dataset,test dataset)\n",
        "- Data cleaning and preprocessing üßê\n",
        "- Feature creation with TF-IDF\n",
        "-Modeling\n",
        "  - do different models  using\n",
        "    - random search trial\n",
        " \n",
        "- Model Evaluation ü•≥      \n",
        "  - Evalute on training dataset and on validation dataset\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HJ5lppmpeZJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the problem. What is the input? What is the output?\n",
        "- The goal of the problem is to predict which fake news or not through analysis the title text. The input is the text in english and The data is raw (contains various forms of words) which we will apply preprocessing on them . The output is the predicted column called `label`, which is binary 0 or 1 as 0 means not fake and 1 means fake. The goal is to estimate the news is fake or not.\n"
      ],
      "metadata": {
        "id": "w9MD9mhIEJM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What data mining function is required?\n",
        "- The data mining function required is classification since the goal is to predict the fake news depend on its title.\n"
      ],
      "metadata": {
        "id": "Id-WfbpVEhL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What could be the challenges? ü§Ø\n",
        "- The challenges could include dealing with noisy data, missing values, and irrelevant or unnecessary words.\n",
        " Also, the text included in the dataset may not be sufficient to accurately predict the news is fake or not, which may require additional data sources or feature engineering."
      ],
      "metadata": {
        "id": "2OaNopdjEhEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the impact?\n",
        "- The impact of accurately predicting status of news is that it can help people to know if if this news is fake or not and we can read and trust it.\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "nZjyNpGDEg7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is an ideal solution? ü§î\n",
        "- My experiment tries to reach to the highest accuracy to predict correct and gives the best benefits to people, in general, an ideal solution would be to develop a machine learning model that accurately predicts \n",
        "the matching  based on the available text, while also being able to handle missing or noisy data. The model should also be easily interpretable, so that businesses can understand the factors that are most important for predicting product ratings. Additionally, the model should be regularly updated with new data to ensure its accuracy over time and develope it regulary.\n"
      ],
      "metadata": {
        "id": "UeRmlT10GdS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "hIbiZJrMRiZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "6BBkapSk0ckd"
      },
      "outputs": [],
      "source": [
        "#import all the important libraries which we need in our experiment.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import svm\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setup our notebook by loading all relevant modules and setting some options\n",
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holoviews as hv\n",
        "import nltk \n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ],
      "metadata": {
        "id": "fxFQDKYOPo67"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load dataset"
      ],
      "metadata": {
        "id": "eSAV4GkSSXDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the train and test dataset to our notebook\n",
        "train_df = pd.read_csv('/content/xy_train.csv')\n",
        "test_df = pd.read_csv('/content/x_test.csv')"
      ],
      "metadata": {
        "id": "YDQSvhG1Po30"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label=train_df[\"label\"]"
      ],
      "metadata": {
        "id": "Bv0k2q89vXgG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show train dataset\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sBZiHJFpPo9s",
        "outputId": "756b5bb7-80e5-403f-b230-19cc91e0a6b5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  \\\n",
              "0      265723   \n",
              "1      284269   \n",
              "2      207715   \n",
              "3      551106   \n",
              "4        8584   \n",
              "...       ...   \n",
              "59995   70046   \n",
              "59996  189377   \n",
              "59997   93486   \n",
              "59998  140950   \n",
              "59999   34509   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "59995      0  \n",
              "59996      1  \n",
              "59997      0  \n",
              "59998      0  \n",
              "59999      1  \n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44961394-7c29-4f2b-9224-70ee3b7b5dae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44961394-7c29-4f2b-9224-70ee3b7b5dae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44961394-7c29-4f2b-9224-70ee3b7b5dae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44961394-7c29-4f2b-9224-70ee3b7b5dae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the id from train dataset \n",
        "train_df.drop(['id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "GcEx1LWY1b8O"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the train dataset\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PSpiuf2o10je",
        "outputId": "baf1af38-311b-4fcb-dc94-89429f5bfd81"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "59995      0  \n",
              "59996      1  \n",
              "59997      0  \n",
              "59998      0  \n",
              "59999      1  \n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bbc1a73-0afc-410b-a7a9-d1142a0b5228\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Obama to Nation: ËÅô\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>Finish Sniper Simo HÁõ≤yhÁõ≤ during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? YouÈà•Ê™á Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>Jeff Bridges Releasing Èà•Ê•Ωleeping Tapes,Èà•?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bbc1a73-0afc-410b-a7a9-d1142a0b5228')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bbc1a73-0afc-410b-a7a9-d1142a0b5228 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bbc1a73-0afc-410b-a7a9-d1142a0b5228');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show the test dataset\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "csPNyP5VPpAr",
        "outputId": "5954f578-cf17-4299-9e37-b3f97e4c89b9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  \\\n",
              "0          0   \n",
              "1          1   \n",
              "2          2   \n",
              "3          3   \n",
              "4          4   \n",
              "...      ...   \n",
              "59146  59146   \n",
              "59147  59147   \n",
              "59148  59148   \n",
              "59149  59149   \n",
              "59150  59150   \n",
              "\n",
              "                                                                                  text  \n",
              "0                                                                           stargazer   \n",
              "1                                                                                 yeah  \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video  \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility  \n",
              "4                                                         \"Believers\" - Hezbollah 2011  \n",
              "...                                                                                ...  \n",
              "59146                                                Bicycle taxi drivers of New Delhi  \n",
              "59147                             Trump blows up GOP's formula for winning House races  \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised  \n",
              "59149                                 Deep down he always wanted to be a ballet dancer  \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car  \n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52592c4f-b9e3-4c71-b131-75218de1255a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52592c4f-b9e3-4c71-b131-75218de1255a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52592c4f-b9e3-4c71-b131-75218de1255a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52592c4f-b9e3-4c71-b131-75218de1255a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make new variable to save id from test dataset\n",
        "id=test_df[\"id\"]\n",
        "id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-tAdYenxh0",
        "outputId": "19aaa04c-6f2e-428c-da5f-0b9d306331ea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            0\n",
              "1            1\n",
              "2            2\n",
              "3            3\n",
              "4            4\n",
              "         ...  \n",
              "59146    59146\n",
              "59147    59147\n",
              "59148    59148\n",
              "59149    59149\n",
              "59150    59150\n",
              "Name: id, Length: 59151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **thoughts and observations for trial 0, plan for trial 1**\n",
        "   - first i will clean and preprocessing the text to be ready to convert to   numeric to can be passed to model to learning on them.\n",
        "   - (plan to trial 1) \n",
        "  - we will start to remove stop words from text as the text in english language also remove tags ,remove single letter chars, convert all whitespaces to single wspace, punctuation and using ` stemming` ."
      ],
      "metadata": {
        "id": "TLiAomYjqrck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning and preprocessing \n",
        "\n",
        "Having consistent and clean data is fundamental for good modeling results. No matter how sophisticated your model the basic principle is: trash in trash out. When dealing with NLP the cleaning and pre processing can differ depending on which model you intend to use. We will use frequency based representation methods for our text. Thus, we usually want to have a pretty thorough manipulation of the input data:\n",
        "\n"
      ],
      "metadata": {
        "id": "WweM8MLcT6ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The code for Trial 1"
      ],
      "metadata": {
        "id": "vAoNIW9RtuAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YWrWpOQVfGPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd039901-228d-49e0-b7ef-f6dcbebdfa5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This transformation has a few benefits. Removing characters and words that don't hold much meaning reduces the size of our data. Moreover, it can improve prediction performance when modeling by lowering the noise in the data. This is because e.g. stop words like prepositions or punctuation won't allow our model to extract additional information / meaning (at least when using simple models). By stemming and lower casing words we make sure that similar words are treated identically. Thus, we can improve model performance again by increasing the number of relevant data points.  \n"
      ],
      "metadata": {
        "id": "2wVSQ0bhVHkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **thoughts and observations for trial 1, plan for trial **\n",
        "  - we notic that stemming retun the words in original without any consideration of meaning so it reduce the data but the accuracy of model lower than the accurary of model while using the lemmatization so i decided to use the liammatization in second trial \n",
        "  - in the second trial i will apply liammetization in preprocessing data as it return every word to original status but with understanding  the meaning of the word and whether it is a verb or a noun .so it more accuracte than stemmer"
      ],
      "metadata": {
        "id": "8kIJCTM_5wgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The code for Trial 2"
      ],
      "metadata": {
        "id": "Cuz-dBMp8a8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import  WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-z√Ä-≈æ,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-z√Ä-≈æ,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            lemmatizer.lemmatize(word) for word in word_tokenize(text) \n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KOtKYpW0dx2",
        "outputId": "c7272afa-de97-458b-f1cf-bd6b4b0f1c67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for train dataset\n",
        "%%time\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "# Clean text\n",
        "train_df[\"text_clean\"] = train_df.loc[ train_df[\"text\"].str.len() > 20, \"text\"]\n",
        "train_df[\"text_clean\"] = train_df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGXyz5U8PpF7",
        "outputId": "8ab17f6a-5491-42cb-b8eb-059b9aeb99dd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 23.3 s, sys: 82.5 ms, total: 23.4 s\n",
            "Wall time: 23.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for test dataset\n",
        "%%time\n",
        "# Clean text\n",
        "test_df[\"text_clean\"] = test_df.loc[ test_df[\"text\"].str.len() > 20, \"text\"]\n",
        "test_df[\"text_clean\"] = test_df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yp7wWGjt6de",
        "outputId": "c4a7ef42-a9de-4fa3-e0ae-d2d4b7fcc8c8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.9 s, sys: 24.6 ms, total: 10.9 s\n",
            "Wall time: 11 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our classification task, we want to be able to recognize whether a text has a positive or negative sentiment. which mean positive if the text is fake and negative if it is not fake, so that our task becomes a binary classification. Keeping them would turn the task into a multi label classification problem, requiring a slightly different modeling approach"
      ],
      "metadata": {
        "id": "iVlObxHbYWfU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "W2GG6UsufGPG"
      },
      "outputs": [],
      "source": [
        "# for train dataset\n",
        "#Create binary classification 0 or 1\n",
        "train_df[\"label_new\"] = 0\n",
        "train_df.loc[train_df[\"label\"] > 0, \"label_new\"] = 1\n",
        "\n",
        "# Drop when any of x missing\n",
        "train_df = train_df[(train_df[\"text_clean\"] != \"\") & (train_df[\"text_clean\"] != \"null\")]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the numbers of classes in trin dataset  \n",
        "train_df[\"label_new\"].value_counts() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV3wuMYBsG42",
        "outputId": "d4e97a29-cf83-484c-c605-e7691f164bbc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    32163\n",
              "1    27827\n",
              "Name: label_new, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# take a copy of train data\n",
        "data_clean = train_df.copy()"
      ],
      "metadata": {
        "id": "yYyJ9zAAPpLr"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "V1jdrynEPpOU",
        "outputId": "16b08396-d28e-428b-905f-a72c2e255c52"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "\n",
              "   label  \\\n",
              "0      0   \n",
              "1      0   \n",
              "2      0   \n",
              "\n",
              "                                                                                            text_clean  \\\n",
              "0  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...   \n",
              "1  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...   \n",
              "2  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...   \n",
              "\n",
              "   label_new  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0d9a2a7-a306-4223-abef-986a0e29fb82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>label_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0d9a2a7-a306-4223-abef-986a0e29fb82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0d9a2a7-a306-4223-abef-986a0e29fb82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0d9a2a7-a306-4223-abef-986a0e29fb82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLEZpBPkfGPJ"
      },
      "source": [
        "### Feature creation with TF-IDF\n",
        "\n",
        "Because classification models cannot deal with text data directly, we need to convert our comments to a numeric representation. All methods have in common that they assign each unique word in a document a unique number. A vector of numbers is created in which each element represents a word. Logically, the length of the vector will equal the number of unique words. In the simplest form (bag of words), a sentence can be represented by such a vector by indicating the presence of a word using a 1 in the appropriate index representing the word. All elements standing for words not included in the sentence will be 0.   \n",
        "Frequency methods improve on this very basic approach. For many applications, `TF-IDF` (term frequency, inverse document frequency) is a good choice. In our case, the `TF` part summarizes how often a word appears in a text in relation to all words. As was mentioned earlier, that is not always a sufficient indicator for a useful word as it might be overly general or be used inflationary in many text. This is where the `IDF` part comes into play. It downscales words that are prevalent in many other text. Consequently, words that are frequent in a text and also specific to it (i.e. they are uncommon in other text) will get a high weight. Unspecific words or those with a low overall frequency will get a low weight.    \n",
        "This is how we apply `TF-IDF` to our text using `scikit-learn`: "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **thoughts and observations for trial 2, plan for trial 3**\n",
        "  - after finishing the cleaning dataset we need to convert it to numeric to become input to model to train so ,we have two choice to apply tfidfvectorizer( analyzer=\"char\" or analyzer=\"word\"), first we will apply analyzer=\"char\" and if it is not good enough we will apply second type `analyzer=\"word`.\n",
        "  - so the plan to trail3 is to apply `analyzer=\"char\"`."
      ],
      "metadata": {
        "id": "jeDzh_9ZHWBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The code for Trail 3"
      ],
      "metadata": {
        "id": "vsxQp0rkJafI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "use pairs of two words (ngram)\n",
        "\"\"\"\n",
        "vectorizer_char = TfidfVectorizer(\n",
        "    analyzer=\"char\", max_df=0.3, min_df=10, ngram_range=(1, 2), norm=\"l2\"\n",
        ")\n",
        "vectorizer_char.fit(data_clean[\"text_clean\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "03s7U4rrJuPY",
        "outputId": "dc2d068e-e8ec-4e5b-9369-c70f90245f51"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char', max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.3, min_df=10, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.3, min_df=10, ngram_range=(1, 2))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  **thoughts and observations for trial 3, plan for trial 4**\n",
        "  - after finishing the cleaning dataset we need to convert it to numeric to become input to model to train and apply tfidfvectorizer of type  analyzer=\"char\"  but  it is not good enough so i will apply the second type `analyzer=\"word`which is good choice.\n",
        "  - so the plan to trail4 is to apply `analyzer=\"word\"`"
      ],
      "metadata": {
        "id": "d_lebeZkKUHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The code of Trail 4"
      ],
      "metadata": {
        "id": "PBAYt5OKX4Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Compute unique word vector with frequencies\n",
        "exclude very uncommon (<10 obsv.) and common (>=30%) words\n",
        "use pairs of two words (ngram)\n",
        "\"\"\"\n",
        "vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"word\", max_df=0.3, min_df=10, ngram_range=(1, 2), norm=\"l2\"\n",
        ")\n",
        "vectorizer.fit(data_clean[\"text_clean\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "HXaUOJXrPpRT",
        "outputId": "eaa452a5-ca39-479d-ef21-a89041036ce4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the text which is cleaned \n",
        "data_clean[\"text_clean\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPiZ7KIGyV4W",
        "outputId": "c39628b4-7f0c-4179-8a03-742920e32853"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        group of friend began to volunteer at homeless shelter after their neighbor protested Seeing ano...\n",
              "1        British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government ha concl...\n",
              "2        In Goodyear released kit that allows PS to be brought to heel http youtube com watch ALXulk cg z...\n",
              "3        Happy Birthday Bob Barker The Price Is Right Host on How He Like to Be Remembered As the man who...\n",
              "4        Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...\n",
              "                                                        ...                                                 \n",
              "59995                             Finish Sniper Simo yh during the invasion of Finland by the USSR colorized\n",
              "59996                                Nigerian Prince Scam took from Kansas man year later he getting it back\n",
              "59997                       Is It Safe To Smoke Marijuana During Pregnancy You Be Surprised Of The Answer no\n",
              "59998                          Julius Caesar upon realizing that everyone in the room ha knife except him bc\n",
              "59999                        Jeff Bridges Releasing leeping Tapes New Album Designed to Help You Fall Asleep\n",
              "Name: text_clean, Length: 59990, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show the test dataset sfter applying preprocessing \n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FJZRzQH7yBoG",
        "outputId": "90d430ea-a270-4b57-a2b7-6c76665c92df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  \\\n",
              "0          0   \n",
              "1          1   \n",
              "2          2   \n",
              "3          3   \n",
              "4          4   \n",
              "...      ...   \n",
              "59146  59146   \n",
              "59147  59147   \n",
              "59148  59148   \n",
              "59149  59149   \n",
              "59150  59150   \n",
              "\n",
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                                                  text_clean  \n",
              "0                                                                        NaN  \n",
              "1                                                                        NaN  \n",
              "2                    PD Phoenix car thief get instruction from YouTube video  \n",
              "3               As Trump Accuses Iran He Has One Problem His Own Credibility  \n",
              "4                                                        Believers Hezbollah  \n",
              "...                                                                      ...  \n",
              "59146                                       Bicycle taxi driver of New Delhi  \n",
              "59147                       Trump blow up GOP formula for winning House race  \n",
              "59148  Napoleon return from his exile on the island of Elba March Colourised  \n",
              "59149                         Deep down he always wanted to be ballet dancer  \n",
              "59150                Toddler miraculously survives story fall landing on car  \n",
              "\n",
              "[59151 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f884fd2-e511-44ed-9faf-a31162954d5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>PD Phoenix car thief get instruction from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>As Trump Accuses Iran He Has One Problem His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>Believers Hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>Bicycle taxi driver of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>Trump blow up GOP formula for winning House race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>Napoleon return from his exile on the island of Elba March Colourised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>Deep down he always wanted to be ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>Toddler miraculously survives story fall landing on car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f884fd2-e511-44ed-9faf-a31162954d5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f884fd2-e511-44ed-9faf-a31162954d5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f884fd2-e511-44ed-9faf-a31162954d5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"id\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXOK4i6e08VY",
        "outputId": "09438e16-8e34-407a-a1c3-24306b38a09e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            0\n",
              "1            1\n",
              "2            2\n",
              "3            3\n",
              "4            4\n",
              "         ...  \n",
              "59146    59146\n",
              "59147    59147\n",
              "59148    59148\n",
              "59149    59149\n",
              "59150    59150\n",
              "Name: id, Length: 59151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observiation about these preprocessing \n",
        "here after i clean the test dataset , i found a big problem as appears `NAN` in the data so i use the original text not using the cleaning text.\n",
        "  - when applying `fillna` , i found the most of data become space\n",
        "  - when drop the `NAN` ,happen problem of reduce data."
      ],
      "metadata": {
        "id": "MxjMnvbmYYnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test = test_df.fillna(axis=\"index\", subset=[\"text_clean\"]).reset_index(drop=True)\n",
        "#test_df=test_df.fillna(' ', inplace=True)"
      ],
      "metadata": {
        "id": "dLDHVEfZyOgv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "uxwMFfHh1Ifg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "bc4ae3fb-2afd-4695-c4cb-d7c32366b626"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  \\\n",
              "0          0   \n",
              "1          1   \n",
              "2          2   \n",
              "3          3   \n",
              "4          4   \n",
              "...      ...   \n",
              "59146  59146   \n",
              "59147  59147   \n",
              "59148  59148   \n",
              "59149  59149   \n",
              "59150  59150   \n",
              "\n",
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                                                  text_clean  \n",
              "0                                                                        NaN  \n",
              "1                                                                        NaN  \n",
              "2                    PD Phoenix car thief get instruction from YouTube video  \n",
              "3               As Trump Accuses Iran He Has One Problem His Own Credibility  \n",
              "4                                                        Believers Hezbollah  \n",
              "...                                                                      ...  \n",
              "59146                                       Bicycle taxi driver of New Delhi  \n",
              "59147                       Trump blow up GOP formula for winning House race  \n",
              "59148  Napoleon return from his exile on the island of Elba March Colourised  \n",
              "59149                         Deep down he always wanted to be ballet dancer  \n",
              "59150                Toddler miraculously survives story fall landing on car  \n",
              "\n",
              "[59151 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-243c6963-be30-4b59-947b-a04cc71c2de8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>PD Phoenix car thief get instruction from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>As Trump Accuses Iran He Has One Problem His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>Believers Hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>Bicycle taxi driver of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>Trump blow up GOP formula for winning House race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>Napoleon return from his exile on the island of Elba March Colourised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>Deep down he always wanted to be ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>Toddler miraculously survives story fall landing on car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-243c6963-be30-4b59-947b-a04cc71c2de8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-243c6963-be30-4b59-947b-a04cc71c2de8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-243c6963-be30-4b59-947b-a04cc71c2de8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izg1CTsPypyu",
        "outputId": "284334e5-bbde-4e9c-9456-70e6b0f79768"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                             stargazer \n",
              "1                                                                                   yeah\n",
              "2                             PD: Phoenix car thief gets instructions from YouTube video\n",
              "3                         As Trump Accuses Iran, He Has One Problem: His Own Credibility\n",
              "4                                                           \"Believers\" - Hezbollah 2011\n",
              "                                              ...                                       \n",
              "59146                                                  Bicycle taxi drivers of New Delhi\n",
              "59147                               Trump blows up GOP's formula for winning House races\n",
              "59148    Napoleon returns from his exile on the island of Elba. (March 1815), Colourised\n",
              "59149                                   Deep down he always wanted to be a ballet dancer\n",
              "59150                          Toddler miraculously survives 6-story fall landing on car\n",
              "Name: text, Length: 59151, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- apply two types of TfidfVectorizer on test dataset."
      ],
      "metadata": {
        "id": "gwslO0R7bPhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the test dataset \n",
        "vectorizer_char_test = TfidfVectorizer(\n",
        "    analyzer=\"char\", max_df=0.3, min_df=10, ngram_range=(1, 2), norm=\"l2\"\n",
        ")\n",
        "vectorizer_char_test.fit(test_df[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "mSJT-TEZKqkH",
        "outputId": "d7668bc5-09a1-46db-c375-4c079005f444"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char', max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.3, min_df=10, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, max_df=0.3, min_df=10, ngram_range=(1, 2))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the test dataset \n",
        "vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"word\", max_df=0.3, min_df=10, ngram_range=(1, 2), norm=\"l2\"\n",
        ")\n",
        "vectorizer.fit(test_df[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "5n3bU3__w8iG",
        "outputId": "eb3f5ff6-c141-4d67-8ba8-2afbc0d32626"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"id\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48CAq2_Mo5ad",
        "outputId": "c96246c6-53e4-4764-8a31-161109d58d31"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            0\n",
              "1            1\n",
              "2            2\n",
              "3            3\n",
              "4            4\n",
              "         ...  \n",
              "59146    59146\n",
              "59147    59147\n",
              "59148    59148\n",
              "59149    59149\n",
              "59150    59150\n",
              "Name: id, Length: 59151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxEMfcOyfGPJ"
      },
      "source": [
        "An important parameter that needs explanation is the `ngram_range`. An `ngram` of one means that you look at each word separately. An `ngram` of two (or `bigram`) means that you take the preceding and following word into account as well. Thus, some context is added. This is helpful because then a model can learn that \"good\" and \"not good\" are different. In our case, in addition to using each word by itself we also add `bigrams` to make use of context.  Let's see some of the created `ngrams` and their indices:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector representation of vocabulary\n",
        "word_vector = pd.Series(vectorizer.vocabulary_).sample(5, random_state=1)\n",
        "print(f\"Unique word (ngram) vector extract:\\n\\n {word_vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IcQzFZ8PpUb",
        "outputId": "7c31f462-f0bd-4fe5-fbbb-d8395e77f24a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique word (ngram) vector extract:\n",
            "\n",
            " the creation    7085\n",
            "ice cream       3377\n",
            "on tree         5066\n",
            "em              2255\n",
            "quickly         5750\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling\n",
        "\n",
        "To test the classification performance of our model. For that, we split our data into a training and a testing set. The former is used to train the model and the latter to evaluate its predictions:"
      ],
      "metadata": {
        "id": "m8qEF3qonzGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### spilt dataset"
      ],
      "metadata": {
        "id": "cSXauVHbdjtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data  30% of data to test set\n",
        "train, test = train_test_split(data_clean, random_state=1, test_size=0.3, shuffle=True)\n",
        "\n",
        "X_train = train[\"text_clean\"]\n",
        "Y_train = train[\"label_new\"]\n",
        "X_test = test[\"text_clean\"]\n",
        "Y_test = test[\"label_new\"]\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_1jbxYPpXc",
        "outputId": "869312b0-44f9-45e0-dbcd-4ea50a21cb45"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41993,)\n",
            "(17997,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training set consists of more than 44k rows and the testing will be performed on more than 14k observations. Now, that we have split our data we can transform the text data into its `TF-IDF` representation:"
      ],
      "metadata": {
        "id": "GjkeGcMzoQsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- applying the trial 3 "
      ],
      "metadata": {
        "id": "_IMyiCjsdvYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "X_train_vec = vectorizer_char.transform(X_train)\n",
        "X_test_vec = vectorizer_char.transform(X_test)\n",
        "X_train_vec.get_shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7QRTkwPK9xw",
        "outputId": "aa51f749-e397-4c47-b24b-6de3f5e41380"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41993, 671)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- applying the trial 4"
      ],
      "metadata": {
        "id": "_o_uuY7qd3Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "X_train_vec = vectorizer.transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "X_train_vec.get_shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix_f3Wy8Ppar",
        "outputId": "b4fb8405-5b8b-4127-e23d-019f033cc3f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41993, 8589)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models to test\n",
        "classifiers = [\n",
        "    LogisticRegression(solver=\"sag\", random_state=1),\n",
        "    LinearSVC(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    XGBClassifier(random_state=1),\n",
        "    MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ),\n",
        "]\n",
        "# get names of the objects in list (too lazy for c&p...)\n",
        "names = [re.match(r\"[^\\(]+\", name.__str__())[0] for name in classifiers]\n",
        "print(f\"Classifiers to test: {names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjhCefqAPpg0",
        "outputId": "29642390-7954-4608-d97e-5fa344522e17"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifiers to test: ['LogisticRegression', 'LinearSVC', 'RandomForestClassifier', 'XGBClassifier', 'MLPClassifier']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test all classifiers and save pred. results on test data\n",
        "results = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(f\"Training classifier: {name}\")\n",
        "    clf.fit(X_train_vec, Y_train)\n",
        "    prediction = clf.predict(X_test_vec)\n",
        "    report = sklearn.metrics.classification_report(Y_test, prediction)\n",
        "    results[name] = report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58m4CtHTPppL",
        "outputId": "e45c108a-8f47-45c9-a8c6-b03d8586f094"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: LogisticRegression\n",
            "Training classifier: LinearSVC\n",
            "Training classifier: RandomForestClassifier\n",
            "Training classifier: XGBClassifier\n",
            "Training classifier: MLPClassifier\n",
            "CPU times: user 2min 41s, sys: 2.71 s, total: 2min 44s\n",
            "Wall time: 2min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF3tjnaSPpuD",
        "outputId": "4c8d8d5a-e9cd-4d58-c81a-53c2a199e891"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      9721\n",
            "           1       0.78      0.80      0.79      8276\n",
            "\n",
            "    accuracy                           0.80     17997\n",
            "   macro avg       0.80      0.80      0.80     17997\n",
            "weighted avg       0.80      0.80      0.80     17997\n",
            "\n",
            "\n",
            "Results for LinearSVC:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81      9721\n",
            "           1       0.77      0.79      0.78      8276\n",
            "\n",
            "    accuracy                           0.79     17997\n",
            "   macro avg       0.79      0.79      0.79     17997\n",
            "weighted avg       0.80      0.79      0.79     17997\n",
            "\n",
            "\n",
            "Results for RandomForestClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.79      0.79      9721\n",
            "           1       0.76      0.76      0.76      8276\n",
            "\n",
            "    accuracy                           0.78     17997\n",
            "   macro avg       0.78      0.78      0.78     17997\n",
            "weighted avg       0.78      0.78      0.78     17997\n",
            "\n",
            "\n",
            "Results for XGBClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.76      0.78      9721\n",
            "           1       0.73      0.79      0.76      8276\n",
            "\n",
            "    accuracy                           0.77     17997\n",
            "   macro avg       0.77      0.77      0.77     17997\n",
            "weighted avg       0.77      0.77      0.77     17997\n",
            "\n",
            "\n",
            "Results for MLPClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.80      0.81      9721\n",
            "           1       0.77      0.80      0.79      8276\n",
            "\n",
            "    accuracy                           0.80     17997\n",
            "   macro avg       0.80      0.80      0.80     17997\n",
            "weighted avg       0.80      0.80      0.80     17997\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Trial 5 \n",
        "- hyperparamter search method (random) with validation set (not cross-validation).\n",
        "- here ,we try different Alghorithm which we pass to pipline to get different accurcy .\n",
        "  - we use randomforestclassifier which give us good accuracy but tries  logistic regression and MLPCassifier to get higher accuracy.\n",
        "  - we define `predefinedspilt` method to prevent happen cross vaildation."
      ],
      "metadata": {
        "id": "YyK-uy4VeKLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we define this method to prevent happening cross validation\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "split_index = [-1 if x in X_train.index else 0 for x in data_clean.index]\n",
        "pds = PredefinedSplit(split_index)"
      ],
      "metadata": {
        "id": "Zu3wQFDZlkU6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use randomforestclassifier"
      ],
      "metadata": {
        "id": "4qKxFroIttI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"RandomForestClassifier\", RandomForestClassifier())])\n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_rf = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"f1_macro\", n_iter=3,cv=pds)\n",
        "pipe_rf.fit(data_clean['text'], data_clean['label'])\n",
        "pickle.dump(pipe_rf, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "id": "M4iNETkUU-7j"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ud5h3C4PfGPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e49b634-ef76-4599-a8f4-2e15516b9452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 69, 'tfidf__max_df': 0.3}\n"
          ]
        }
      ],
      "source": [
        "print(pipe_rf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use linearSVC"
      ],
      "metadata": {
        "id": "32YKfiU3t1oT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dzPWNBVLfGPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0adf5f-f8d0-499a-9ec7-cbbaca829173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.95 s, sys: 613 ms, total: 10.6 s\n",
            "Wall time: 30.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"svc\", LinearSVC())])\n",
        "\n",
        "# define parameter space to test # runtime 19min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 3)],\n",
        "    \"tfidf__max_df\": [0.5],\n",
        "    \"tfidf__min_df\": [5],\n",
        "    \"svc__C\": np.arange(0.2, 1, 0.15),\n",
        "}\n",
        "pipe_svc_clf = RandomizedSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\",  n_iter=3,cv=pds)\n",
        "pipe_svc_clf.fit(data_clean['text'], data_clean['label'])\n",
        "pickle.dump(pipe_svc_clf, open(\"./pipe_svc_clf.pck\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = pipe_svc_clf.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNTeOyb_gEUK",
        "outputId": "9559f815-fedd-4720-f376-0a07d8869dfa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 5, 'tfidf__max_df': 0.5, 'svc__C': 0.6499999999999999}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trial 6\n",
        "- after trying different model , we will try another model to get higher accuracy\n",
        "- such as these models ,XGBClassifier ."
      ],
      "metadata": {
        "id": "TEJ_9gqivHVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **The code For Trial 6** "
      ],
      "metadata": {
        "id": "un9804U8vyd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use XGBClassifier"
      ],
      "metadata": {
        "id": "n9R5hmwBuQKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"XGBClassifier\", XGBClassifier())])\n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_XGB = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"f1_macro\", n_iter=3,cv=pds)\n",
        "pipe_XGB.fit(data_clean['text'], data_clean['label'])\n",
        "pickle.dump(pipe_XGB, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "id": "v_vhT8GEuYHU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = pipe_XGB.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40rYDFGduZJL",
        "outputId": "74fb2d30-2255-436e-94a9-5c5c85660054"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 50, 'tfidf__max_df': 0.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use LogisticRegression"
      ],
      "metadata": {
        "id": "_MS9kJnYt9QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LogisticRegression\", LogisticRegression(solver=\"sag\", random_state=1))])\n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_logistic = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"f1_macro\", n_iter=3,cv=pds)\n",
        "pipe_logistic.fit(data_clean['text'], data_clean['label'])\n",
        "pickle.dump(pipe_logistic, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "id": "W3DyImrT9m1e"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8nBgjjMFfGPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b9f398-8ad1-4220-8e90-ce73a915852f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 15, 'tfidf__max_df': 0.3}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_logistic.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use MLPClassifier"
      ],
      "metadata": {
        "id": "KDuxXHHwucUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"MLPClassifier\", MLPClassifier())])\n",
        "\n",
        "# define parameter space to test # runtime 35min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_MLP = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"f1_macro\", n_iter=3,cv=pds)\n",
        "pipe_MLP.fit(data_clean['text'], data_clean['label'])\n",
        "pickle.dump(pipe_MLP, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "id": "P1dSDoByunkj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = pipe_MLP.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0S5CH5Sundb",
        "outputId": "df33e820-7982-4e3d-8199-4162462a0230"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 14, 'tfidf__max_df': 0.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(data_clean['text'], data_clean['label'])\n",
        "pipe_pred = pipe_logistic.predict(X_test)\n",
        "report = sklearn.metrics.classification_report(Y_test, pipe_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNHvBLd8-ZYH",
        "outputId": "a9c890fb-6942-4459-b078-26ba93a3da62"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87      9721\n",
            "           1       0.84      0.86      0.85      8276\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.86     17997\n",
            "   macro avg       0.57      0.57      0.57     17997\n",
            "weighted avg       0.86      0.86      0.86     17997\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "RZnFddOQfGPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f56405-f032-4837-8061-afe3bb4a5aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96      9721\n",
            "           1       0.95      0.96      0.95      8276\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96     17997\n",
            "   macro avg       0.64      0.64      0.64     17997\n",
            "weighted avg       0.96      0.96      0.96     17997\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(data_clean['text'], data_clean['label'])\n",
        "pipe_pred = pipe_rf.predict(X_test)\n",
        "report = sklearn.metrics.classification_report(Y_test, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## submission"
      ],
      "metadata": {
        "id": "VBy-ux3-pA20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_df['id']\n",
        "submission['label'] = pipe_logistic.predict_proba(test_df[\"text\"])[:,1]\n",
        "submission.to_csv('logistic.csv',index=False)"
      ],
      "metadata": {
        "id": "BQG1WNu1UuRS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_df['id']\n",
        "submission['label'] = pipe_rf.predict_proba(test_df[\"text\"])[:,1]\n",
        "submission.to_csv('randmforest.csv',index=False)"
      ],
      "metadata": {
        "id": "EqxDKpGSln2k"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_df['id']\n",
        "submission['label'] = pipe_XGB.predict_proba(test_df[\"text\"])[:,1]\n",
        "submission.to_csv('XGB.csv',index=False)"
      ],
      "metadata": {
        "id": "JWKmCnpEVrPJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create submission file\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = test_df['id']\n",
        "submission['label'] = pipe_MLP.predict_proba(test_df[\"text\"])[:,1]\n",
        "submission.to_csv('mlp.csv',index=False)"
      ],
      "metadata": {
        "id": "9ydgUq80ViK3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Z5n-KNnN6O",
        "outputId": "679fcc3e-add9-42f3-f926-268ea483b499"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            0\n",
              "1            1\n",
              "2            2\n",
              "3            3\n",
              "4            4\n",
              "         ...  \n",
              "59146    59146\n",
              "59147    59147\n",
              "59148    59148\n",
              "59149    59149\n",
              "59150    59150\n",
              "Name: id, Length: 59151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saOUqBjMmBik",
        "outputId": "addaada4-16d9-4560-99f8-d5cdea56538e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                                             stargazer \n",
              "1                                                                                   yeah\n",
              "2                             PD: Phoenix car thief gets instructions from YouTube video\n",
              "3                         As Trump Accuses Iran, He Has One Problem: His Own Credibility\n",
              "4                                                           \"Believers\" - Hezbollah 2011\n",
              "                                              ...                                       \n",
              "59146                                                  Bicycle taxi drivers of New Delhi\n",
              "59147                               Trump blows up GOP's formula for winning House races\n",
              "59148    Napoleon returns from his exile on the island of Elba. (March 1815), Colourised\n",
              "59149                                   Deep down he always wanted to be a ballet dancer\n",
              "59150                          Toddler miraculously survives 6-story fall landing on car\n",
              "Name: text, Length: 59151, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oj33p80oE_A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions and their answers"
      ],
      "metadata": {
        "id": "gzDHQBLdgRVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
        "- Character n-gram and word n-gram are two types of n-gram models used in natural language processing.\n",
        "\n",
        "- Character n-gram models represent words as sequences of characters. For example, the word \"hello\" can be represented as \"h\", \"he\", \"hel\", \"hell\", \"ello\", \"llo\", and \"lo\". These models are useful when dealing with languages that have complex morphologies or when dealing with misspelled text. However, they suffer from the OOV (Out of Vocabulary) issue, as they cannot represent words that are not in the training data.\n",
        "\n",
        "- Word n-gram models represent words as sequences of words. For example, the sentence \"The quick brown fox jumps over the lazy dog\" can be represented as \"The quick\", \"quick brown\", \"brown fox\", \"fox jumps\", \"jumps over\", \"over the\", and \"the lazy\". These models are useful when dealing with languages that have simple morphologies, and they are less likely to suffer from the OOV issue, as they can represent any word that appears in the training data.\n",
        "\n",
        "- In conclusion, character n-gram models are useful in certain situations, but they tend to suffer more from the OOV issue compared to word n-gram models. Word n-gram models, on the other hand, are more commonly used and less likely to suffer from the OOV issue."
      ],
      "metadata": {
        "id": "V4Ttdu0vlGSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the difference between stop word removal and stemming? Are these techniques language-dependent?\n",
        "- Stop word removal and stemming are two common techniques used in natural language processing.\n",
        "\n",
        "- Stop word removal involves removing commonly used words, such as \"the\", \"and\", \"a\", etc., from a text. These words are considered to have little semantic value and are often ignored by search engines and other text processing tools. Stop word removal is language-dependent because the list of stop words varies depending on the language being analyzed.\n",
        "\n",
        "- Stemming involves reducing words to their basic form or root, by removing any suffixes or prefixes. For example, the words \"running\", \"runner\", and \"runs\" would all be reduced to \"run\". This technique is used to group together words with similar meanings and to reduce the number of unique words in a text. Stemming can be language-dependent because different languages have different rules for word inflections and morphology.\n",
        "\n",
        "- In summary, stop word removal and stemming are both techniques used to preprocess text in natural language processing. Stop word removal involves removing commonly used words, while stemming involves reducing words to their basic form or root. Both techniques can be language-dependent, as the rules for stop words and word inflections vary between languages."
      ],
      "metadata": {
        "id": "gq5YTixexloY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Is tokenization techniques language dependent? Why?\n",
        "- Yes,These issues of tokenization are language-specific. It thus requires the language of the document to be known. Language identification based on classifiers that use short character subsequences as features is highly effective; most languages have distinctive signature patterns.\n",
        "- Tokenization techniques are language-dependent because different languages have different rules for separating words, phrases, and sentences. For example, in English, words are often separated by spaces, while in Chinese, there are no spaces between words. Therefore, tokenization for English text can be done by splitting the text on whitespace, while tokenization for Chinese text requires more complex techniques, such as using a dictionary to identify word boundaries.\n",
        "\n",
        "- Moreover, some languages have complex morphologies or compound words, which require more sophisticated tokenization techniques. For instance, in German, nouns are often compounded together to form long words, and these words need to be split into their constituent parts to correctly analyze the text.\n",
        "\n",
        "- In summary, tokenization techniques are language-dependent because they rely on language-specific rules for separating words, phrases, and sentences. Language-specific tokenization techniques must be used to ensure that the text is correctly analyzed and processed.\n"
      ],
      "metadata": {
        "id": "RZO7dvN9xlks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
        "\n",
        "- Count vectorizer and TF-IDF vectorizer are two commonly used techniques for vectorizing text data in natural language processing.\n",
        "\n",
        "- Count vectorizer creates a matrix where each row represents a document, and each column represents a word in the vocabulary. The values in the matrix represent the number of times each word appears in each document. This technique is simple and effective, but it does not take into account the importance of rare words or the frequency of words in the overall corpus.\n",
        "\n",
        "- TF-IDF vectorizer, on the other hand, creates a matrix where each row represents a document, and each column represents a word in the vocabulary. The values in the matrix represent the importance of each word in each document, taking into account the frequency of the word in the document and the frequency of the word in the overall corpus. This technique is more sophisticated and effective at capturing the importance of words in each document.\n",
        "\n",
        "- It is not feasible to use all possible n-grams for vectorizing text data because the number of possible n-grams increases exponentially with the length of the n-gram. This can lead to a very high-dimensional feature space, which can be difficult to process and can result in overfitting. Therefore, it is important to select a subset of n-grams that are most informative for the task at hand.\n",
        "\n",
        "- The selection of n-grams depends on the specific task and the characteristics of the data. In general, it is recommended to start with unigrams (single words) and bigrams (pairs of adjacent words) and then experiment with higher-order n-grams if necessary. It is also important to consider the frequency of the n-grams in the data and to remove any n-grams that are too rare or too common. Additionally, domain-specific knowledge can be used to select relevant n-grams for the task at hand."
      ],
      "metadata": {
        "id": "iV3vD-dTxlhm"
      }
    }
  ]
}